% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/performance_cv.R
\name{performance_cv}
\alias{performance_cv}
\title{A function to generate the performance evaluation metrices based on cross validation results.}
\usage{
performance_cv(y, X, cv_f = list(svm = svm_f, randomForest = randomForest_f),
  boundaries = c(0, 0.5), performance_metrices = c("AUROC", "ACC", "ERR",
  "SENS", "SPEC", "MCC"), k = 10, p = 1, plot_AUC = T, save_table = T,
  save_plot_data = F, ...)
}
\arguments{
\item{y}{a \code{factor} that contains the binary response variable with levels 1,0 for binary classification. This argument could be a \code{list} of factors.}

\item{X}{a \code{matrix} that contains the features, nrow(X) = length(y). This argument could be a \code{list} of matrixes.}

\item{cv_f}{a function that gets the input argument named y , X_train, and X_test, and output is the real numbered decision values for X_test.

For example, the returned values can be the votes proportions for random forest, and it can also be the decision values for SVM.

This package contains buildin predictor functions for you to use, such as: \code{\link{svm_f}} and \code{\link{randomForest_f}}
However, it is still recommended to create your own function with tunned parameters.

This argument could be a \code{list} of functions, Default to be list(svm_f, randomForest_f).}

\item{boundaries}{The decision boundaries used when quantify performance metrices with fixed alpha, should be a numeric vector with its length equal to \code{cv_f}.
Default: c(0,0.5), SVM is 0, and Random forest is .5.}

\item{k}{the number of folds used in cross validation, default 10.}

\item{p}{the number of parallels used, default equals 1, recommend to use p = k on server.}

\item{plot_AUC}{plot and save the ROC curve or not, default TRUE.}

\item{save_table}{save the performance table or not, default TRUE.}

\item{save_plot_data}{save the data used to plot the ROC curve, default FALSE.}

\item{...}{additional arguments passed to \code{cv_f}}

\item{performance_matrices}{a character vector indicating the performance metrices returned, default is \code{c("AUROC","ACC","ERR","SENS","SPEC","MCC")},

"AUROC" represents: Area under receiver operating characteristic curve.

"ACC" represents: Accuracy.

"ERR" represents: Error rate.

"SENS" represents: Sensitivity.

"SPEC" represents: Specificity.

"MCC" represents: Matthews correlation coefficient.}
}
\value{
a \code{data.frame} that contains comprehensive performance report after cross validation.
}
\details{
\code{performance} conduct performance evaluation on a machine learning binary classifier using cross validation.
This is a convenient function to get a neat and efficient result of performance evaluation after cross validation.

The missing values will not be imputed by default, and the dimensions containing missing values will be dropped.
}
\seealso{
\code{\link{view_tables}} to visualize the output.
}
